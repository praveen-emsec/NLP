{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quP9Jz7pDpH_",
        "outputId": "004dcbc5-17fb-4c51-d624-69f7945ef879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.0 MB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.3\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import faiss\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKbHHjGCD6oX",
        "outputId": "34665ff6-3f6e-4359-b425-d3919dc77430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "FCCRFpd0G_Nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('medium_Data.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "id": "gew9p0HNDzfc",
        "outputId": "17ee22a5-82c3-4632-adec-111ef017ebbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Titles            Authors  \\\n",
              "0    Please Consider the Racial Impact of Your Hall...       Savala Nolan   \n",
              "1    That Time We Burned Down Players’ Houses in Ul...         Tim Cotten   \n",
              "2    The Wonderful Outcome of the Ice Bucket Challenge        Jamie Cohen   \n",
              "3              Why Should You Care About the Bar Exam?          Dan Canon   \n",
              "4        Please Don’t Tell My Daughter She’s Beautiful      Kerala Taylor   \n",
              "..                                                 ...                ...   \n",
              "304   How I Kept My Sense of Humor Through Vision Loss       Nancy Solari   \n",
              "305  The true scientific meaning of Mercury enterin...       Ethan Siegel   \n",
              "306  The Feelings Monster, building a character wit...   Microsoft Design   \n",
              "307  Feeling Overwhelmed? You Need an MVD—That’s Mi...  Rebecca Pendleton   \n",
              "308        Type Casting — or: The Comic Sans of Errors       Boris Müller   \n",
              "\n",
              "            Dates                                              Links  \\\n",
              "0          Oct 17  https://momentum.medium.com/i-beg-you-consider...   \n",
              "1           Oct 3  https://blog.cotten.io/that-time-we-burned-dow...   \n",
              "2          Sep 30  https://newanddigital.medium.com/the-long-payo...   \n",
              "3          Sep 27  https://medium.com/i-taught-the-law/why-should...   \n",
              "4          Oct 11  https://keralataylor.medium.com/please-dont-te...   \n",
              "..            ...                                                ...   \n",
              "304        Sep 15  https://betterhumans.pub/how-i-kept-my-sense-o...   \n",
              "305        Sep 15  https://medium.com/starts-with-a-bang/the-true...   \n",
              "306         Sep 6  https://medium.com/microsoft-design/the-feelin...   \n",
              "307  May 27, 2021  https://index.medium.com/feeling-overwhelmed-y...   \n",
              "308   Mar 9, 2019  https://borism.medium.com/type-casting-or-the-...   \n",
              "\n",
              "                                              Contents  \n",
              "0    Oh, it’s that time of year again! So here is a...  \n",
              "1    Ultima Online is celebrating its 25th annivers...  \n",
              "2    The water had to be ice cold and you had to be...  \n",
              "3    You didn’t take the bar exam. That’s probably ...  \n",
              "4    I have two beautiful children.I might be biase...  \n",
              "..                                                 ...  \n",
              "304  My diagnosis of retinitis pigmentosa at age 16...  \n",
              "305  Throughout almost all of the year, you can see...  \n",
              "306  On designing for mental health and the power o...  \n",
              "307  I’\\nm a product director at a corporate financ...  \n",
              "308  A\\ncommon question in my first-year design sem...  \n",
              "\n",
              "[309 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80416a1a-ddcf-43e3-9245-0f1a32e8cfe4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Titles</th>\n",
              "      <th>Authors</th>\n",
              "      <th>Dates</th>\n",
              "      <th>Links</th>\n",
              "      <th>Contents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Please Consider the Racial Impact of Your Hall...</td>\n",
              "      <td>Savala Nolan</td>\n",
              "      <td>Oct 17</td>\n",
              "      <td>https://momentum.medium.com/i-beg-you-consider...</td>\n",
              "      <td>Oh, it’s that time of year again! So here is a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>That Time We Burned Down Players’ Houses in Ul...</td>\n",
              "      <td>Tim Cotten</td>\n",
              "      <td>Oct 3</td>\n",
              "      <td>https://blog.cotten.io/that-time-we-burned-dow...</td>\n",
              "      <td>Ultima Online is celebrating its 25th annivers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Wonderful Outcome of the Ice Bucket Challenge</td>\n",
              "      <td>Jamie Cohen</td>\n",
              "      <td>Sep 30</td>\n",
              "      <td>https://newanddigital.medium.com/the-long-payo...</td>\n",
              "      <td>The water had to be ice cold and you had to be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why Should You Care About the Bar Exam?</td>\n",
              "      <td>Dan Canon</td>\n",
              "      <td>Sep 27</td>\n",
              "      <td>https://medium.com/i-taught-the-law/why-should...</td>\n",
              "      <td>You didn’t take the bar exam. That’s probably ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Please Don’t Tell My Daughter She’s Beautiful</td>\n",
              "      <td>Kerala Taylor</td>\n",
              "      <td>Oct 11</td>\n",
              "      <td>https://keralataylor.medium.com/please-dont-te...</td>\n",
              "      <td>I have two beautiful children.I might be biase...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>How I Kept My Sense of Humor Through Vision Loss</td>\n",
              "      <td>Nancy Solari</td>\n",
              "      <td>Sep 15</td>\n",
              "      <td>https://betterhumans.pub/how-i-kept-my-sense-o...</td>\n",
              "      <td>My diagnosis of retinitis pigmentosa at age 16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>The true scientific meaning of Mercury enterin...</td>\n",
              "      <td>Ethan Siegel</td>\n",
              "      <td>Sep 15</td>\n",
              "      <td>https://medium.com/starts-with-a-bang/the-true...</td>\n",
              "      <td>Throughout almost all of the year, you can see...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>The Feelings Monster, building a character wit...</td>\n",
              "      <td>Microsoft Design</td>\n",
              "      <td>Sep 6</td>\n",
              "      <td>https://medium.com/microsoft-design/the-feelin...</td>\n",
              "      <td>On designing for mental health and the power o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307</th>\n",
              "      <td>Feeling Overwhelmed? You Need an MVD—That’s Mi...</td>\n",
              "      <td>Rebecca Pendleton</td>\n",
              "      <td>May 27, 2021</td>\n",
              "      <td>https://index.medium.com/feeling-overwhelmed-y...</td>\n",
              "      <td>I’\\nm a product director at a corporate financ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>308</th>\n",
              "      <td>Type Casting — or: The Comic Sans of Errors</td>\n",
              "      <td>Boris Müller</td>\n",
              "      <td>Mar 9, 2019</td>\n",
              "      <td>https://borism.medium.com/type-casting-or-the-...</td>\n",
              "      <td>A\\ncommon question in my first-year design sem...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>309 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80416a1a-ddcf-43e3-9245-0f1a32e8cfe4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-80416a1a-ddcf-43e3-9245-0f1a32e8cfe4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-80416a1a-ddcf-43e3-9245-0f1a32e8cfe4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "alphanumeric = lambda x: re.sub(r\"\"\"\\S*\\d{1}\\w*\"\"\", ' ', x)\n",
        "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
        "new_line = lambda x: re.sub(r'(?<!\\.)\\n', '', x)\n",
        "\n",
        "df['Titles'] = df.Titles.map(alphanumeric).map(punc_lower).map(new_line)\n",
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        },
        "id": "R0a9XnNBEsfp",
        "outputId": "aacb28ce-2996-408b-b84d-cb7e05206690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Titles                Authors  \\\n",
              "0  please consider the racial impact of your hall...           Savala Nolan   \n",
              "1  that time we burned down players’ houses in ul...             Tim Cotten   \n",
              "2  the wonderful outcome of the ice bucket challenge            Jamie Cohen   \n",
              "3            why should you care about the bar exam               Dan Canon   \n",
              "4      please don’t tell my daughter she’s beautiful          Kerala Taylor   \n",
              "5       how google search is reinventing itself in               Eric Chung   \n",
              "6           chatgpt is having a thomas edison moment           Thomas Smith   \n",
              "7                                how to be a tourist           Roblin Meeks   \n",
              "8     theses on the concept of nonhuman intelligence  Blaise Aguera y Arcas   \n",
              "9                            a  ’s guide to mastodon          Jeremy Littau   \n",
              "\n",
              "    Dates                                              Links  \\\n",
              "0  Oct 17  https://momentum.medium.com/i-beg-you-consider...   \n",
              "1   Oct 3  https://blog.cotten.io/that-time-we-burned-dow...   \n",
              "2  Sep 30  https://newanddigital.medium.com/the-long-payo...   \n",
              "3  Sep 27  https://medium.com/i-taught-the-law/why-should...   \n",
              "4  Oct 11  https://keralataylor.medium.com/please-dont-te...   \n",
              "5   Oct 7  https://uxdesign.cc/how-google-search-is-reinv...   \n",
              "6   Dec 9  https://tomsmith585.medium.com/chatgpt-is-havi...   \n",
              "7  Sep 26  https://humanparts.medium.com/how-to-be-a-tour...   \n",
              "8  Sep 19  https://medium.com/@blaisea/1011-theses-on-the...   \n",
              "9   Nov 8  https://jeremylittau.medium.com/a-n00bs-guide-...   \n",
              "\n",
              "                                            Contents  \n",
              "0  Oh, it’s that time of year again! So here is a...  \n",
              "1  Ultima Online is celebrating its 25th annivers...  \n",
              "2  The water had to be ice cold and you had to be...  \n",
              "3  You didn’t take the bar exam. That’s probably ...  \n",
              "4  I have two beautiful children.I might be biase...  \n",
              "5  Google is completely changing the way that sea...  \n",
              "6  ChatGPT is blowing up. Twitter is inundated wi...  \n",
              "7  Paris in the summer is hot and not really buil...  \n",
              "8  When Gottfried Wilhelm Leibniz discovered bina...  \n",
              "9  From “The Axe Forgets” — S1E5 of Andor on Disn...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f155611-205d-4778-ac5c-c4c16af77015\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Titles</th>\n",
              "      <th>Authors</th>\n",
              "      <th>Dates</th>\n",
              "      <th>Links</th>\n",
              "      <th>Contents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>please consider the racial impact of your hall...</td>\n",
              "      <td>Savala Nolan</td>\n",
              "      <td>Oct 17</td>\n",
              "      <td>https://momentum.medium.com/i-beg-you-consider...</td>\n",
              "      <td>Oh, it’s that time of year again! So here is a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>that time we burned down players’ houses in ul...</td>\n",
              "      <td>Tim Cotten</td>\n",
              "      <td>Oct 3</td>\n",
              "      <td>https://blog.cotten.io/that-time-we-burned-dow...</td>\n",
              "      <td>Ultima Online is celebrating its 25th annivers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the wonderful outcome of the ice bucket challenge</td>\n",
              "      <td>Jamie Cohen</td>\n",
              "      <td>Sep 30</td>\n",
              "      <td>https://newanddigital.medium.com/the-long-payo...</td>\n",
              "      <td>The water had to be ice cold and you had to be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>why should you care about the bar exam</td>\n",
              "      <td>Dan Canon</td>\n",
              "      <td>Sep 27</td>\n",
              "      <td>https://medium.com/i-taught-the-law/why-should...</td>\n",
              "      <td>You didn’t take the bar exam. That’s probably ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>please don’t tell my daughter she’s beautiful</td>\n",
              "      <td>Kerala Taylor</td>\n",
              "      <td>Oct 11</td>\n",
              "      <td>https://keralataylor.medium.com/please-dont-te...</td>\n",
              "      <td>I have two beautiful children.I might be biase...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>how google search is reinventing itself in</td>\n",
              "      <td>Eric Chung</td>\n",
              "      <td>Oct 7</td>\n",
              "      <td>https://uxdesign.cc/how-google-search-is-reinv...</td>\n",
              "      <td>Google is completely changing the way that sea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>chatgpt is having a thomas edison moment</td>\n",
              "      <td>Thomas Smith</td>\n",
              "      <td>Dec 9</td>\n",
              "      <td>https://tomsmith585.medium.com/chatgpt-is-havi...</td>\n",
              "      <td>ChatGPT is blowing up. Twitter is inundated wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>how to be a tourist</td>\n",
              "      <td>Roblin Meeks</td>\n",
              "      <td>Sep 26</td>\n",
              "      <td>https://humanparts.medium.com/how-to-be-a-tour...</td>\n",
              "      <td>Paris in the summer is hot and not really buil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>theses on the concept of nonhuman intelligence</td>\n",
              "      <td>Blaise Aguera y Arcas</td>\n",
              "      <td>Sep 19</td>\n",
              "      <td>https://medium.com/@blaisea/1011-theses-on-the...</td>\n",
              "      <td>When Gottfried Wilhelm Leibniz discovered bina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>a  ’s guide to mastodon</td>\n",
              "      <td>Jeremy Littau</td>\n",
              "      <td>Nov 8</td>\n",
              "      <td>https://jeremylittau.medium.com/a-n00bs-guide-...</td>\n",
              "      <td>From “The Axe Forgets” — S1E5 of Andor on Disn...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f155611-205d-4778-ac5c-c4c16af77015')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f155611-205d-4778-ac5c-c4c16af77015 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f155611-205d-4778-ac5c-c4c16af77015');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords') \n",
        "from nltk.tokenize import word_tokenize \n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haZJTkigEsio",
        "outputId": "ccd225f3-1fff-44a1-fd6a-baf8eea2f3b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Titles'] = df['Titles'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
      ],
      "metadata": {
        "id": "Dkr4ra0sEslS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask =df.isnull()\n",
        "mask_ = np.sum(mask)\n",
        "mask_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qKJysLiGAr1",
        "outputId": "7cf070d3-46cd-449f-8449-a58b38ae618b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Titles       0\n",
              "Authors      0\n",
              "Dates        0\n",
              "Links        0\n",
              "Contents    11\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset=[\"Contents\"])"
      ],
      "metadata": {
        "id": "U7j5NlVrVAra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask =df.isnull()\n",
        "mask_ = np.sum(mask)\n",
        "mask_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFPgrZ-MV8up",
        "outputId": "d4f39e55-d92e-47f5-ad70-da4db33295c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Titles      0\n",
              "Authors     0\n",
              "Dates       0\n",
              "Links       0\n",
              "Contents    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"data.csv\")\n"
      ],
      "metadata": {
        "id": "EbZVNnQVWq39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhtbNPwNEdd9",
        "outputId": "031af64d-acdb-41f4-9376-a013e19be97d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "with open(\"data.csv\", \"r\") as file:\n",
        "    for line in file:\n",
        "        data.append(line.strip())"
      ],
      "metadata": {
        "id": "4oCLIKpJEghg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "from transformers import AutoModel\n",
        "bert_model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "\n",
        "input_data = \" \".join(df[\"Titles\"].tolist())\n",
        "\n",
        "tokens = bert_tokenizer.tokenize(input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xP7ERBcgN4m",
        "outputId": "ea31ab84-eb0e-4a54-9ae2-1d62e10b9c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BMZcJIfsGbS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = [token for token in tokens if isinstance(token, str)]"
      ],
      "metadata": {
        "id": "YLmW-K0oe8X5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FydJTEolEnHZ",
        "outputId": "c536821f-07ab-4857-8050-3ec62cb931a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 54.1 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 32.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel\n",
        "import torch\n",
        "\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "embeddings = []\n",
        "for tokens in tokens:\n",
        "    # Convert the tokens list to a one-dimensional array or list\n",
        "    tokens_1d = [token for token in tokens if token not in stop_words]\n",
        "    print(tokens_1d)\n",
        "\n",
        "    # Convert the tokens array or list to a tensor\n",
        "    tokens_tensor = torch.tensor(tokens_1d)\n",
        "    # Create an embedding for the tensor using the BERT model\n",
        "    embedding = model(tokens_tensor)[0][0]s\n",
        "    embeddings.append(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "ZJsRNYg5GLuI",
        "outputId": "d6fd6262-fec7-4c75-ef11-8836aa3d22b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[',', 'T', 'l', 'e', ',', 'A', 'u', 'h', 'r', ',', 'D', 'e', ',', 'L', 'n', 'k', ',', 'C', 'n', 'e', 'n']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-7091e89df8d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_1d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Convert the tokens array or list to a tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtokens_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_1d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# # Create an embedding for the tensor using the BERT model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nlp = spacy.load(\"en_core_web_sm\")\n",
        "# vectors = [nlp(text).vector for text in df[\"Titles\"]]\n",
        "# vectors = np.array(vectors)\n",
        "# vectors = np.atleast_2d(vectors)\n",
        "# mask = np.isnan(vectors)\n",
        "# index = faiss.IndexFlatL2(vectors[0].shape[0])\n",
        "# index\n",
        "# index.add(vectors)"
      ],
      "metadata": {
        "id": "Luwu0ttRGN61"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}